{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kütüphaneleri İçe Aktarıyoruz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kütüphaneler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "\n",
    "import sklearn.metrics as mt\n",
    "import tensorflow as tf\n",
    "\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kütüphanelerden sonra indirdiğimiz veri setini projemizle aynı klasörün içerisine koyuyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSet='dataSet/'\n",
    "\n",
    "allImages = pathlib.Path(dataSet)\n",
    "imageDs = len(list(allImages.glob('*/*.jpg'))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Daha sonra Görseller hakıında bilgi edinebilmek için bir kaç tanesinin boyutunu yazdırıyoruz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image=list(allImages.glob('*/*.jpg'))\n",
    "if image:\n",
    "    frame=image[0]\n",
    "    with Image.open(frame) as img:\n",
    "        width, height = img.size\n",
    "        print(f\"Resim: {frame}, Boyut: {width}x{height}\")\n",
    "        frame=image[299]\n",
    "    with Image.open(frame) as img:\n",
    "        width, height = img.size\n",
    "        print(f\"Resim: {frame}, Boyut: {width}x{height}\")\n",
    "        frame=image[1190]\n",
    "    with Image.open(frame) as img:\n",
    "        width, height = img.size\n",
    "        print(f\"Resim: {frame}, Boyut: {width}x{height}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kullandığımız veri setinin eğitim ve doğrulama olarak ayrılmasını ve görüntü işlme kullanacağımız model için ön hazırlığını yapıyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainDs = tf.keras.utils.image_dataset_from_directory( \n",
    "    allImages, \n",
    "    validation_split=0.2, \n",
    "    subset=\"training\", \n",
    "    seed=123, \n",
    "    image_size=(180, 180), \n",
    "    batch_size=32) \n",
    "\n",
    "valDs = tf.keras.utils.image_dataset_from_directory( \n",
    "    allImages, \n",
    "    validation_split=0.2, \n",
    "    subset=\"validation\", \n",
    "    seed=123, \n",
    "    image_size=(180,180), \n",
    "    batch_size=32) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veri Setimize ait sınıfları hazırladığımız veriler üzerinden alalım ve görüntüleyelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = trainDs.class_names \n",
    "print(classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Şimdi hazırladığımız veri setinden karışık olarak 30 adet görseli görselleştirelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "for images, labels in trainDs.take(1): \n",
    "    for i in range(30): \n",
    "        plt.rcParams.update({'text.color': \"red\",\n",
    "                     'axes.labelcolor': \"green\"})\n",
    "        ax = plt.subplot(6, 5, i + 1) \n",
    "        plt.subplots_adjust(left=0.1,\n",
    "                    bottom=0.1, \n",
    "                    right=0.9, \n",
    "                    top=0.9, \n",
    "                    wspace=0.4, \n",
    "                    hspace=0.4)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\")) \n",
    "        plt.title(classes[labels[i]]) \n",
    "        \n",
    "        plt.axis(\"off\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bu aşamada iki tane model hazırladık eğitim için ilk model hızlı bir çalışma süresine sahip çünkü daha basit bir model kullanmak isterseniz ilk modeli yorum satırından çıkararak ve ikinci modeli yorum satırına alarak kullanabilirsiniz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"      \n",
    "classesNum = len(classes) \n",
    "\n",
    "  #kendi oluşturduğumz model\n",
    "MLmodel = tf.keras.Sequential([ \n",
    "    tf.keras.layers.Rescaling(1./255, input_shape=(180,180, 3)), \n",
    "    tf.keras.layers.Conv2D(16, 3, padding='same', activation='relu'), \n",
    "    tf.keras.layers.MaxPooling2D(), \n",
    "    tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'), \n",
    "    tf.keras.layers.MaxPooling2D(), \n",
    "    tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'), \n",
    "    tf.keras.layers.MaxPooling2D(), \n",
    "    tf.keras.layers.Flatten(), \n",
    "    tf.keras.layers.Dense(128, activation='relu'), \n",
    "    tf.keras.layers.Dense(classesNum) \n",
    "]) \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "İkinci model olarak kullanılam MobileNetV3Large modeli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLmodel=tf.keras.applications.MobileNetV3Large(\n",
    "    input_shape=None,\n",
    "    alpha=1.0,\n",
    "    minimalistic=False,\n",
    "    include_top=True,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    classes=1000,\n",
    "    pooling=None,\n",
    "    dropout_rate=0.2,\n",
    "    classifier_activation=\"softmax\",\n",
    "    include_preprocessing=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modeli yazırladıktan sonra modeli derleyerek eğitime hazır hale getiriyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLmodel.compile(optimizer='adam', \n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy( \n",
    "                  from_logits=True), \n",
    "              metrics=['accuracy']) \n",
    "MLmodel.summary() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelin eğitilmesinde büyük bir rol oynayan epoch sayısını yani verinin eğitim sürecinin uzunluğunu belirtip modeli eğitime sokuyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=10\n",
    "\n",
    "history = MLmodel.fit( \n",
    "  trainDs, \n",
    "  validation_data=valDs, \n",
    "  epochs=epochs \n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eğitim tamalandıktan sonra eğitim sürecinde ve sonunda model eğitim peformansını değerlendirmemizi sağlayan parametre ve grafikleri görüntülüyoruz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model eğitim grafiği"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy \n",
    "acc = history.history['accuracy'] \n",
    "val_acc = history.history['val_accuracy'] \n",
    "  \n",
    "#loss \n",
    "loss = history.history['loss'] \n",
    "val_loss = history.history['val_loss'] \n",
    "  \n",
    "#epochs  \n",
    "epochs_range = range(epochs) \n",
    "  \n",
    "# eğitim sonucu grafikleri\n",
    "plt.figure(figsize=(8, 8)) \n",
    "plt.subplot(1, 2, 1) \n",
    "plt.plot(epochs_range, acc, label='Training Accuracy') \n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy') \n",
    "plt.legend(loc='lower right') \n",
    "plt.title('Training and Validation Accuracy') \n",
    "  \n",
    "\n",
    "plt.subplot(1, 2, 2) \n",
    "plt.plot(epochs_range, loss, label='Training Loss') \n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss') \n",
    "plt.legend(loc='upper right') \n",
    "plt.title('Training and Validation Loss') \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eğitim sonrası tahminler ve doğrulamalarını gösteren Confusion Matrix ve doğruluk değerlerinin hesaplanması ve görselleştirilmesi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Tahminler\n",
    "y_pred_probs = MLmodel.predict(valDs)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "# Gerçek etiketler\n",
    "y_true = np.concatenate([y for x, y in valDs], axis=0)\n",
    "\n",
    "# Karışıklık matrisini hesaplama\n",
    "conf_matrix = mt.confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# F1 skoru ve geri çağırma değerlerini hesapla\n",
    "f1 = mt.f1_score(y_true, y_pred, average='weighted')\n",
    "recall = mt.recall_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "# Sonuçları yazdırma\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "\n",
    "# Karışıklık matrisini görselleştirme\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
